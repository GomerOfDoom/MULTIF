# Deterministic optimization of small climb problem
# Usage:
# dakota -i det-opt.in -o det-opt.out

environment
    output_precision = 16
    tabular_data
    tabular_data_file = 'simulation_uq_int.dat'
    method_pointer = 'OPTIM'

method
    id_method = 'OPTIM'
    model_pointer = 'OPTIM_M'
        npsol_sqp
        max_iterations = 100
        max_function_evaluations = 10000
        convergence_tolerance = 1.e-3
        constraint_tolerance  = 1.e-3

model
    id_model = 'OPTIM_M'
    single
        variables_pointer = 'OPTIM_V'
        responses_pointer = 'OPTIM_R'
        interface_pointer = 'OPTIM_I'

variables
    id_variables = 'OPTIM_V'
    continuous_design = 21
	#initial_point	0.2269444448167199	0.2369444448167199	0.2469444448167199	0.2574	0.2584	0.2684	0.2784	0.3514	0.3862	0.4538	0.536	0.259	0.241	0.2364667968340999	0.2343756857974439	0.2353756857974439	0.235775685797444	0.240885685795911	0.240885685795911	0.243	0.2438 
        initial_point     0.2124  0.2269  0.2734  0.3218  0.323   0.3343  0.3474  0.4392  0.4828  0.5673  0.67    0.3238  0.2981  0.2817  0.2787  0.2797  0.2807  0.2936  0.2978  0.3038  0.3048
        lower_bounds      0.1699  0.1815  0.2187  0.2574  0.2584  0.2674  0.2779  0.3514  0.3862  0.4538  0.536   0.259   0.2385  0.2254  0.223   0.2238  0.2246  0.2349  0.2382  0.243   0.2438
        upper_bounds      0.2549  0.2723  0.3281  0.3862  0.3876  0.4012  0.4169  0.527   0.5794  0.6808  0.804   0.3886  0.3577  0.338   0.3344  0.3356  0.3368  0.3523  0.3574  0.3646  0.3658
        descriptors      'c6x' 'c7x' 'c8x' 'c9x' 'c11x' 'c12x' 'c13x' 'c14x' 'c15x' 'c16x' 'c17x' 'c6y' 'c7y' 'c8y' 'c9y' 'c12y' 'c13y' 'c14y' 'c15y' 'c16y' 'c17y'
        scale_types = 'auto'
    linear_inequality_constraint_matrix =
        -5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
         100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
           0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
           0.    0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
            0.     0.     0.  1000. -1000.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
           0.    0.    0.    0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
           0.    0.    0.    0.    0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
           0.    0.    0.    0.    0.    0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
           0.    0.    0.    0.    0.    0.    0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
           0.    0.    0.    0.    0.    0.    0.    0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
           0.    0.    0.    0.    0.    0.    0.    0.    0.  100. -100.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
         0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          3.07219662  0.          0.          0.          0.          0.          0.          0.          0.          0.
         0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          3.07219662  0.          0.          0.          0.          0.          0.          0.          0.
         0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          3.07219662  0.          0.          0.          0.          0.          0.          0.
         0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          3.07219662  0.          0.          0.          0.          0.          0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0. -1000.     0.     0.  1000.     0.     0.     0.     0.     0.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0. -1000.     0.  1000.     0.     0.     0.     0.     0.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0. -1000.  1000.     0.     0.     0.     0.     0.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.  1000. -1000.     0.     0.     0.     0.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.  1000.     0. -1000.     0.     0.     0.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.  1000.     0.     0. -1000.     0.     0.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.  1000.     0.     0.     0. -1000.     0.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.  1000.     0.     0.     0.     0. -1000.     0.
            0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.  1000.     0.     0.     0.     0.     0. -1000.
        -2.69662921  0.          0.          0.          0.          0.          0.          0.          0.          0.          0.         -1.49812734  0.          0.          0.          0.          0.          0.          0.          0.          0.
        -2.1691974   0.          0.          0.          0.          0.          0.          0.          0.          0.          0.          4.33839479  0.          0.          0.          0.          0.          0.          0.          0.          0.
         1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.   0.   0.   0.
         0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.   0.   0.
         0.   0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.   0.
         1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.  0.  0.  0.  0.  0.  0.  0.
         0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.  0.  0.  0.  0.  0.  0.
         0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.  0.  0.  0.  0.  0.
         0.   0.   0.   0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.
         0.   0.   0.   0.   0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.
         0.   0.   0.   0.   0.   0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.
         0.   0.   0.   0.   0.   0.   0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.
         0.   0.   0.   0.   0.   0.   0.   0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.
         0.   0.   0.   0.   0.   0.   0.   0.   0.   1.8 -1.8  0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.
         0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.  0.  0.  0.  0.
         0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.  0.  0.  0.
         0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.  0.  0.
         0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.  0.
         0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.  0.
         0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -2.  2.
          1.  -1.   0.   0.   0.   0.   0.   0.   0.   0.   0. -20.  20.   0.   0.   0.   0.   0.   0.   0.   0.
          0.   1.  -1.   0.   0.   0.   0.   0.   0.   0.   0.   0. -20.  20.   0.   0.   0.   0.   0.   0.   0.
         0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5. -5.  0.  0.  0.  0.  0.  0.
         0.    0.    0.    0.    1.   -1.    0.    0.    0.    0.    0.    0.    0.    0.   -6.25  6.25  0.    0.    0.    0.    0.
         0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -5.  5.  0.  0.  0.  0.
         0.          0.          0.          0.          0.          0.          1.         -1.          0.          0.          0.          0.          0.          0.          0.          0.         -3.33333333  3.33333333  0.          0.          0.
         0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0. -5.  5.  0.  0.
          0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.   0.   0.   0. -10.  10.   0.
          0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.   0.   0.   0. -20.  20.
          0.   0.   0.   0.  -1.   1.   0.   0.   0.   0.   0.   0.   0.   0.  25. -25.   0.   0.   0.   0.   0.
          0.   0.   0.   0.   0.  -1.   1.   0.   0.   0.   0.   0.   0.   0.   0.  25. -25.   0.   0.   0.   0.
          0.           0.           0.           0.           0.           0.          -1.           1.           0.           0.           0.           0.           0.           0.           0.           0.          14.28571429 -14.28571429   0.           0.           0.
         0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.  0.  0.
          0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.   0.   0.   0.  20. -20.   0.
          0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  -1.   0.   0.   0.   0.   0.   0.   0.   0.  20. -20.
    linear_inequality_upper_bounds = -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     1.00000000
                                     1.00000000
                                     1.00000000
                                     1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     -1.00000000
                                     1.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000
                                     0.00000000

responses
    id_responses = 'OPTIM_R'
    objective_functions = 1
    nonlinear_inequality_constraints = 1  # Exp val of M, T
  	nonlinear_inequality_lower_bounds = 23000.
  	nonlinear_inequality_upper_bounds = 1.e+50
    numerical_gradients
        method_source dakota
        interval_type forward
        fd_gradient_step_size = 1.e-3
    no_hessians

interface
    id_interface = 'OPTIM_I'
    analysis_driver = 'bash driver_uq_int.sh'
        fork # asynchronous evaluation_concurrency = 4
        work_directory named 'run_uq_int'
        link_files 'runModel.py' 'general_gradients.cfg' 'make_responses' 'postproc'
	copy_files '../../ML_code/train.py' '../../ML_code/train.dat' '../../ML_code/shaowuML.py' '/../../ML_code/shaowuML.pyc' '/../../ML_code/config.pkl' '/../../ML_code/ensemble_model.pkl' '/../../ML_code/normalize_dict.pkl'
        directory_tag
        directory_save
        file_save
        parameters_file = 'params.in'
        results_file = 'responses.out'
